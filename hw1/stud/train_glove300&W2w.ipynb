{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6sAA4Ngg5iVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7ca71e4-afb3-41ef-8247-cddf3f44a146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### USE WITH COLAB"
      ],
      "metadata": {
        "id": "dSCbq5RzuJAh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emFTRKU-5dK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1cd2741-90d3-4f25-91ab-95a45bd06094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: {0} /content\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "cwd = os.getcwd()\n",
        "\n",
        "# Print the current working directory\n",
        "print(\"Current working directory: {0}\",cwd)\n",
        "\n",
        "checkpoinW2W = torch.load('/content/drive/MyDrive/NLP/nlp2022-hw1-main/model/model_w2w.pt')\n",
        "checkpoinGLOVE = torch.load('/content/drive/MyDrive/NLP/nlp2022-hw1-main/model/model_glove300.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t72QM_fK5dLB"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class LSTM_Glovo(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim_Glovo, hidden_dim_Glovo):\n",
        "        super(LSTM_Glovo, self).__init__()\n",
        "\n",
        "\n",
        "\n",
        "        #glovo\n",
        "        self.lstm_glovo = torch.nn.LSTM(embedding_dim_Glovo, hidden_dim_Glovo, batch_first=True,num_layers=2,bidirectional=True,dropout=0.3)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, sentence_glovo):\n",
        "\n",
        "\n",
        "        lstm_out_glovo, _ = self.lstm_glovo(sentence_glovo)\n",
        "       \n",
        "\n",
        "        return lstm_out_glovo\n",
        "\n",
        "class LSTM_W2W(torch.nn.Module):\n",
        "\n",
        "    def __init__(self,embedding_dim_w2w, hidden_dim_w2w):\n",
        "        super(LSTM_W2W, self).__init__()\n",
        "\n",
        "        #w2w\n",
        "        self.lstm_w2w = torch.nn.LSTM(embedding_dim_w2w, hidden_dim_w2w, batch_first=True,num_layers=2,bidirectional=True,dropout=0.3)\n",
        "\n",
        "\n",
        "    def forward(self, sentence_w2w):\n",
        "\n",
        "\n",
        "        lstm_out_w2w, _ = self.lstm_w2w(sentence_w2w)\n",
        "\n",
        "\n",
        "        return lstm_out_w2w\n",
        "\n",
        "class Classifier(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim_glovo, embedding_dim_w2w, tagset_size):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "        self.hidden_classifier_0 = torch.nn.Linear(1200,600)\n",
        "        self.hidden_classifier_1 = torch.nn.Linear(600, tagset_size*tagset_size)\n",
        "        self.hidden_classifier_2 = torch.nn.Linear(tagset_size*tagset_size, tagset_size)\n",
        "        self.drop = torch.nn.Dropout(p=0.4)\n",
        "        self.soft_max = torch.nn.Softmax(dim=2)\n",
        "\n",
        "\n",
        "    def forward(self, input_glovo, inputw2w):\n",
        "\n",
        "        input=torch.cat((input_glovo, inputw2w), 2)\n",
        "\n",
        "\n",
        "        x = self.drop(input)\n",
        "        x = self.hidden_classifier_0(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.hidden_classifier_1(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.hidden_classifier_2(x)\n",
        "        tag_scores=self.soft_max(x)\n",
        "    \n",
        "\n",
        "\n",
        "        return tag_scores\n",
        "\n",
        "\n",
        "\n",
        "model_glovo=LSTM_Glovo(300,300)\n",
        "model_w2w=LSTM_W2W(300,300)\n",
        "\n",
        "model_w2w.load_state_dict(checkpoinW2W, strict=False)\n",
        "model_glovo.load_state_dict(checkpoinGLOVE, strict=False)\n",
        "\n",
        "\n",
        "model_classifier=Classifier(300,300,13)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from typing import Dict, Iterator, List, Union, Optional\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "from gensim.models import KeyedVectors\n",
        "import numpy as np\n",
        "'''\n",
        "Input : path to dataset\n",
        "Output : List of dictionaries, each dictionary is a Id Sentence composed by \"sentence\" and \"labels\" field\n",
        "'''\n",
        "\n",
        "def dataset_creation(path):\n",
        "  \n",
        "\n",
        "  dataset = [] \n",
        "  words = []\n",
        "  labels = []\n",
        "\n",
        "  with open(path) as file:\n",
        "      tsv_file = csv.reader(file, delimiter=\"\\t\")\n",
        "      for line in tsv_file:\n",
        "          \n",
        "          #print(line)\n",
        "\n",
        "\n",
        "          if line:\n",
        "\n",
        "\n",
        "              if line[0] == '#':\n",
        "                  #print('new line------------------------------')\n",
        "\n",
        "                  new_sentence={\n",
        "                      \"sentence\":words,\n",
        "                      \"labels\":labels\n",
        "                  }\n",
        "                  \n",
        "                  dataset.append(new_sentence)\n",
        "                                  \n",
        "                  words=[]\n",
        "                  labels=[]\n",
        "              else:\n",
        "                  word=line[0]\n",
        "                  label=line[1]\n",
        "                  words.append(word)\n",
        "                  labels.append(label)\n",
        "\n",
        "          \n",
        "  dataset.pop(0)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "\n",
        "def vocabulary_and_lableDictionary(data):\n",
        "    \n",
        "\n",
        "    PAD_TOKEN = \"<PAD>\"\n",
        "    UNK_TOKEN = \"<UNK>\"\n",
        "\n",
        "    # vocabulary from word to index\n",
        "    vocab = {PAD_TOKEN: 0, UNK_TOKEN: 1}\n",
        "    # iterate over the words of the dataset\n",
        "    for word in [word for sample in data for word in sample[\"sentence\"]]:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = len(vocab)\n",
        "\n",
        "    label_dict = {}\n",
        "    for label in [label for sample in data for label in sample[\"labels\"]]:\n",
        "        if label not in label_dict:\n",
        "            label_dict[label] = len(label_dict)\n",
        "\n",
        "    #print(\"Word to Index:\")\n",
        "    #print(vocab)\n",
        "\n",
        "    #print(\"Label to Index:\")\n",
        "    #print(label_dict)\n",
        "\n",
        "    return vocab, label_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_torch_embedding_layer(weights: KeyedVectors, padding_idx: int = 0, freeze: bool = False):\n",
        "\n",
        "  vectors = weights.vectors\n",
        "  # random vector for pad\n",
        "  pad = np.random.rand(1, vectors.shape[1])\n",
        "  print(pad.shape)\n",
        "  # mean vector for unknowns\n",
        "  unk = np.mean(vectors, axis=0, keepdims=True)\n",
        "  print(unk.shape)\n",
        "  # concatenate pad and unk vectors on top of pre-trained weights\n",
        "  vectors = np.concatenate((pad, unk, vectors))\n",
        "  # convert to pytorch tensor\n",
        "  vectors = torch.FloatTensor(vectors)\n",
        "  # and return the embedding layer\n",
        "  return torch.nn.Embedding.from_pretrained(vectors, padding_idx=padding_idx, freeze=freeze)"
      ],
      "metadata": {
        "id": "6VRdgP64Dkye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SC3IYVN35dLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "943933dc-4764-46f7-b17a-513ea904ed8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Your path for TRAIN dataset is : /data/train.tsv\n",
            "\n",
            "Your path for DEV dataset is : /data/dev.tsv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "#to get the current working directory\n",
        "current_dir = Path(os.getcwd())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Create Dataset for \n",
        "Train\n",
        "'''\n",
        "main_dir=current_dir.parent.parent.absolute()\n",
        "dataset_path=os.path.join(main_dir, \"data/train.tsv\")\n",
        "data_train=dataset_creation('/content/drive/MyDrive/NLP/nlp2022-hw1-main/data/train.tsv')\n",
        "vocab,label_dict=vocabulary_and_lableDictionary(data_train)\n",
        "\n",
        "\n",
        "'''\n",
        "Create Dataset for \n",
        "Test\n",
        "'''\n",
        "dataset_path_dev=os.path.join(main_dir, \"data/dev.tsv\")\n",
        "data_test=dataset_creation('/content/drive/MyDrive/NLP/nlp2022-hw1-main/data/dev.tsv')\n",
        "print('\\nYour path for TRAIN dataset is :',dataset_path)\n",
        "print('\\nYour path for DEV dataset is :',dataset_path_dev)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "dict_path_w2w=os.path.join(main_dir, \"hw1/data/Dict_W2W.npy\")\n",
        "weight_path_w2w=os.path.join(main_dir, \"hw1/data/Weight_W2W.npy\")\n",
        "\n",
        "Dictionary_w2w2 = np.load('/content/drive/MyDrive/NLP/nlp2022-hw1-main/hw1/data/Dict_W2W.npy',allow_pickle='TRUE').item()\n",
        "weight_w2w = np.load('/content/drive/MyDrive/NLP/nlp2022-hw1-main/hw1/data/Weight_W2W.npy',allow_pickle='TRUE')\n",
        "weight_tensor_w2w=torch.from_numpy(weight_w2w)\n",
        "\n",
        "\n",
        "dict_path_glove=os.path.join(main_dir, \"hw1/data/Dict_glove.npy\")\n",
        "weight_path_glove=os.path.join(main_dir, \"hw1/data/Weight_glove.npy\")\n",
        "\n",
        "Dictionary_glove = np.load('/content/drive/MyDrive/NLP/nlp2022-hw1-main/hw1/data/Dict_Glove.npy',allow_pickle='TRUE').item()\n",
        "weight_glove = np.load('/content/drive/MyDrive/NLP/nlp2022-hw1-main/hw1/data/Weight_Glove.npy',allow_pickle='TRUE')\n",
        "weight_tensor_glove=torch.from_numpy(weight_glove)\n",
        "    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dejOk_E5dLK"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "from typing import Dict, List\n",
        "\n",
        "# collate fn\n",
        "PAD_TOKEN = \"<PAD>\"\n",
        "UNK_TOKEN = \"<UNK>\"\n",
        "\n",
        "\n",
        "\n",
        "def prepare_batch_glove(batch: List[Dict]) -> List[Dict]:\n",
        "  # extract features and labels from batch\n",
        "  x = [sample[\"sentence\"] for sample in batch]\n",
        "  y = [sample[\"labels\"] for sample in batch]\n",
        "  # convert words to index\n",
        "  x = [[Dictionary_glove.get(word, Dictionary_glove[UNK_TOKEN]) for word in sample] for sample in x]\n",
        "  # convert labels to index\n",
        "  y = [[label_dict.get(label) for label in sample] for sample in y]\n",
        "  # convert features to tensor and pad them\n",
        "  x = pad_sequence(\n",
        "    [torch.as_tensor(sample) for sample in x],\n",
        "    batch_first=True,\n",
        "    padding_value=Dictionary_glove.get(PAD_TOKEN)\n",
        "  )\n",
        "  # convert and pad labels too\n",
        "  y = pad_sequence(\n",
        "    [torch.as_tensor(sample) for sample in y],\n",
        "    batch_first=True,\n",
        "    padding_value=0\n",
        "  )\n",
        "  return {\"x\": x, \"y\": y}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def prepare_batch_w2w(batch: List[Dict]) -> List[Dict]:\n",
        "  # extract features and labels from batch\n",
        "  x = [sample[\"sentence\"] for sample in batch]\n",
        "  y = [sample[\"labels\"] for sample in batch]\n",
        "  # convert words to index\n",
        "  x = [[Dictionary_w2w2.get(word, Dictionary_w2w2[UNK_TOKEN]) for word in sample] for sample in x]\n",
        "  # convert labels to index\n",
        "  y = [[label_dict.get(label) for label in sample] for sample in y]\n",
        "  # convert features to tensor and pad them\n",
        "  x = pad_sequence(\n",
        "    [torch.as_tensor(sample) for sample in x],\n",
        "    batch_first=True,\n",
        "    padding_value=Dictionary_w2w2.get(PAD_TOKEN)\n",
        "  )\n",
        "  # convert and pad labels too\n",
        "  y = pad_sequence(\n",
        "    [torch.as_tensor(sample) for sample in y],\n",
        "    batch_first=True,\n",
        "    padding_value=0\n",
        "  )\n",
        "  return {\"x\": x, \"y\": y}\n",
        "\n",
        "\n",
        "def prepare_batch(batch: List[Dict]) -> List[Dict]:\n",
        "  # extract features and labels from batch\n",
        "  \n",
        "  x_ = [sample[\"sentence\"] for sample in batch]\n",
        "  y = [sample[\"labels\"] for sample in batch]\n",
        "\n",
        "  # convert words to index\n",
        "  x1 = [[Dictionary_w2w2.get(word, Dictionary_w2w2[UNK_TOKEN]) for word in sample] for sample in x_]\n",
        "  x2 = [[Dictionary_glove.get(word, Dictionary_glove[UNK_TOKEN]) for word in sample] for sample in x_]\n",
        "  # convert labels to index\n",
        "  y = [[label_dict.get(label) for label in sample] for sample in y]\n",
        "  # convert features to tensor and pad them\n",
        "  x1 = pad_sequence(\n",
        "    [torch.as_tensor(sample) for sample in x1],\n",
        "    batch_first=True,\n",
        "    padding_value=Dictionary_w2w2.get(PAD_TOKEN)\n",
        "  )\n",
        "\n",
        "    \n",
        "  x2 = pad_sequence(\n",
        "    [torch.as_tensor(sample) for sample in x2],\n",
        "    batch_first=True,\n",
        "    padding_value=Dictionary_glove.get(PAD_TOKEN)\n",
        "  )\n",
        "    \n",
        "\n",
        "  # convert and pad labels too\n",
        "  y = pad_sequence(\n",
        "    [torch.as_tensor(sample) for sample in y],\n",
        "    batch_first=True,\n",
        "    padding_value=0\n",
        "  )\n",
        "  return {\"x\": [x1,x2], \"y\": y}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HElX1MXZ5dLM"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset \n",
        "\n",
        "#________________________________________________________________________\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index) -> List[Dict]:\n",
        "        return self.data[index]\n",
        "#________________________________________________________________________\n",
        "class Custom_Embedding():\n",
        "\n",
        "    def __init__(self, weights, dict, batch, by_id ) -> None:\n",
        "\n",
        "        self.weights = weights\n",
        "        self.dict = dict\n",
        "        self.batch = batch\n",
        "        self.weights_leng = len(self.weights[0,:])\n",
        "        self.by_id = by_id\n",
        "    \n",
        "\n",
        "    def get_weight(self,token):\n",
        "\n",
        "\n",
        "        if(self.by_id == False):\n",
        "            try : index_token = self.dict[token]\n",
        "            except : \n",
        "                #print('missing')\n",
        "                index_token = self.dict['UNK']\n",
        "        else:\n",
        "            return self.weights[token,:]\n",
        "\n",
        "        \n",
        "    \n",
        "        return self.weights[index_token,:]\n",
        "\n",
        "\n",
        "    def embedd(self,list_words):\n",
        "\n",
        "        list=[]\n",
        "        \n",
        "        if(self.batch == False):\n",
        "\n",
        "            for word in list_words:\n",
        "                list.append(self.get_weight(word).tolist())\n",
        "            \n",
        "\n",
        "            \n",
        "\n",
        "            return torch.tensor(list)\n",
        "        \n",
        "        elif(self.batch == True):\n",
        "\n",
        "            max_pad = longest(list_words)\n",
        "            #print('max padd',max_pad)\n",
        "\n",
        "            \n",
        "\n",
        "            for sentence in list_words:\n",
        "\n",
        "                current_lenght = len(sentence)\n",
        "                #print('current :',current_lenght)\n",
        "                sencence=[]\n",
        "                for word in sentence:\n",
        "                    sencence.append(self.get_weight(word).tolist())\n",
        "                \n",
        "                \n",
        "\n",
        "                if(max_pad>current_lenght):\n",
        "                    #print('padding')\n",
        "                    listofzeros = [0] * self.weights_leng\n",
        "\n",
        "                    while max_pad>current_lenght:\n",
        "                        #print('padding now')\n",
        "                        sencence.append(listofzeros)\n",
        "                        #print('new leng',len(sencence))\n",
        "                        current_lenght = len(sencence)\n",
        "                \n",
        "\n",
        "                #print('append list',len(sencence))\n",
        "                list.append(sencence)\n",
        "\n",
        "\n",
        "            return torch.tensor(list)\n",
        "#________________________________________________________________________\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def longest(list1):\n",
        "    longest_list = max(len(elem) for elem in list1)\n",
        "    return longest_list\n",
        "\n",
        "\n",
        "\n",
        "# data loader parameters\n",
        "collate_fn_w2w = prepare_batch_w2w # the function that will prepare the data for the model\n",
        "collate_fn_glove = prepare_batch_glove # the function that will prepare the data for the model\n",
        "collate_fn = prepare_batch\n",
        "batch_sizes = 32\n",
        "num_workers = min(os.cpu_count(), 4)  # it is usually 4 workers per GPU\n",
        "is_train_dataloader = False # we don\"t want to shuffle dev and test data\n",
        "\n",
        "\n",
        "\n",
        "#NERDdataset for both training and test(from dev.tsv)\n",
        "train_dataset = NERDataset(data_train)\n",
        "dev_dataset=NERDataset(data_test)\n",
        "\n",
        "\n",
        "\n",
        "#DataLoader definition\n",
        "\n",
        "train_data_loader_glove = DataLoader(\n",
        "  train_dataset,\n",
        "  collate_fn=collate_fn_glove,\n",
        "  shuffle=is_train_dataloader,\n",
        "  batch_size=batch_sizes,\n",
        "  num_workers=num_workers,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "train_data_loader_w2w = DataLoader(\n",
        "  train_dataset,\n",
        "  collate_fn=collate_fn_w2w,\n",
        "  shuffle=is_train_dataloader,\n",
        "  batch_size=batch_sizes,\n",
        "  num_workers=num_workers,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#collate_fn_w2w or collate_fn_glove\n",
        "dev_data_loader = DataLoader(\n",
        "  dev_dataset,\n",
        "  collate_fn=collate_fn_w2w,\n",
        "  shuffle=is_train_dataloader,\n",
        "  batch_size=batch_sizes,\n",
        "  num_workers=num_workers,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_data_loader = DataLoader(\n",
        "  train_dataset,\n",
        "  collate_fn=collate_fn,\n",
        "  shuffle=is_train_dataloader,\n",
        "  batch_size=batch_sizes,\n",
        "  num_workers=num_workers,\n",
        ")\n",
        "\n",
        "dev_data_loader = DataLoader(\n",
        "  dev_dataset,\n",
        "  collate_fn=collate_fn,\n",
        "  shuffle=is_train_dataloader,\n",
        "  batch_size=batch_sizes,\n",
        "  num_workers=num_workers,\n",
        ")\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_glovo.to(device)\n",
        "model_w2w.to(device)\n",
        "model_classifier.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBhBj6yTFlSW",
        "outputId": "c41bd8a5-6ed2-459b-b7cc-7ec0768cf4f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (hidden_classifier_0): Linear(in_features=1200, out_features=600, bias=True)\n",
              "  (hidden_classifier_1): Linear(in_features=600, out_features=169, bias=True)\n",
              "  (hidden_classifier_2): Linear(in_features=169, out_features=13, bias=True)\n",
              "  (drop): Dropout(p=0.4, inplace=False)\n",
              "  (soft_max): Softmax(dim=2)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_classifier.parameters(), lr=0.1, momentum=0.9)\n",
        "emb_glove = Custom_Embedding(weight_tensor_glove,Dictionary_glove,True,True)\n",
        "emb_w2w = Custom_Embedding(weight_tensor_w2w,Dictionary_w2w2,True,True)\n",
        "\n",
        "\n",
        "i=0\n",
        "loss_history = []\n",
        "loss_history_val = []\n",
        "\n",
        "\n",
        "f1_history = []\n",
        "f1_history_val = []\n",
        "\n",
        "for epoch in range(50):\n",
        "\n",
        "  count=0\n",
        "  accuracy_epoch=0\n",
        "  total_prediction=[]\n",
        "  total_labels=[]\n",
        "  running_loss = 0\n",
        "  model_classifier.train()\n",
        "  \n",
        "\n",
        "  for ext_counter,batch in enumerate(train_data_loader):\n",
        "    \n",
        "    \n",
        "    model_classifier.zero_grad()\n",
        "\n",
        "    batch_x= batch['x']\n",
        "    batch_x_w2w = batch_x[0]\n",
        "    batch_x_g = batch_x[1]\n",
        "\n",
        "    \n",
        "    batch_y = batch['y']\n",
        "    #or is the same\n",
        "    #batch_y = batch_['y']\n",
        "\n",
        "    #GLOVE EMBEDDING\n",
        "    batch_x_g = emb_glove.embedd(batch_x_g.tolist())\n",
        "    batch_x_w2w = emb_w2w.embedd(batch_x_w2w.tolist())\n",
        "    #print(batch_x.size())\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    input_glovo = batch_x_g.to(device)\n",
        "    input_w2w = batch_x_w2w.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      model_glovo.eval()\n",
        "      model_w2w.eval()\n",
        "      prediction_lstm_glovo=model_glovo.forward(input_glovo)\n",
        "      prediction_lstm_w2w=model_w2w.forward(input_w2w)\n",
        "      model_glovo.train()\n",
        "      model_w2w.train()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    prediction = model_classifier.forward(prediction_lstm_glovo,prediction_lstm_w2w)\n",
        "\n",
        "    #print('Predicted: ',prediction.size())\n",
        "    #print('Ground Truth: ',batch_y.size())\n",
        "    sizes=prediction.size()\n",
        "    #print(sizes[0])\n",
        "    l0=sizes[0]\n",
        "    l1=sizes[1]\n",
        "    l2=sizes[2]\n",
        "    l3=l0*l1\n",
        "\n",
        "    new_size = (l3,l2)\n",
        "    prediction_batch = torch.reshape(prediction,new_size)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    target_batch = torch.flatten(batch_y)\n",
        "    target_batch = target_batch.to(device)\n",
        "    \n",
        "\n",
        "  \n",
        "\n",
        "    loss = loss_function(prediction_batch,target_batch)\n",
        "    running_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    pre_accu=torch.argmax(prediction_batch, dim=1)\n",
        "    pre_accu = pre_accu.to('cpu')\n",
        "    target_batch = target_batch.to('cpu')\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "    #print('predited',pre_accu)\n",
        "    #print('target',target_batch)\n",
        "\n",
        "\n",
        "    train_acc = torch.sum(pre_accu == target_batch)\n",
        "\n",
        "\n",
        "    batch_train_acc = (np.array(train_acc))/(target_batch.size())\n",
        "\n",
        "    accuracy_epoch=accuracy_epoch+batch_train_acc\n",
        "    \n",
        "\n",
        "    \n",
        "    total_prediction=total_prediction+(pre_accu.tolist())\n",
        "    total_labels=total_labels+(target_batch.tolist())\n",
        "    count+=1\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "  \n",
        "\n",
        "  running_loss_avg = (running_loss/count)\n",
        "  loss_history.append(running_loss_avg)\n",
        "  f1_score_epoch = f1_score(total_labels, total_prediction,average=None)\n",
        "  f1_score_epoch_macro = f1_score(total_labels, total_prediction,average='macro')\n",
        "  f1_history.append(f1_score_epoch_macro)\n",
        "  print('\\n\\nEPOCHS n.'+str(epoch))\n",
        "  print('______________________TRAIN_______________________________')\n",
        "  print('f1 score :',f1_score_epoch)\n",
        "  print('accuracy training :',accuracy_epoch/count)\n",
        "  print('f1 score macro: ',f1_score_epoch_macro)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  '''\n",
        "  validation on this epoch\n",
        "  \n",
        "  '''\n",
        "  model_classifier.eval()\n",
        "  with torch.no_grad():\n",
        "\n",
        "    count_val=0\n",
        "    accuracy_epoch_val=0\n",
        "    total_prediction_val=[]\n",
        "    total_labels_val=[]\n",
        "    running_loss_val = 0\n",
        "\n",
        "    for ext_counter,batch in enumerate(dev_data_loader):\n",
        "\n",
        "      batch_x= batch['x']\n",
        "      batch_x_w2w = batch_x[0]\n",
        "      batch_x_g = batch_x[1]\n",
        "      \n",
        "      batch_y = batch['y']\n",
        "      #or is the same\n",
        "      #batch_y = batch_['y']\n",
        "\n",
        "      #GLOVE EMBEDDING\n",
        "      batch_x_g = emb_glove.embedd(batch_x_g.tolist())\n",
        "      batch_x_w2w = emb_w2w.embedd(batch_x_w2w.tolist())\n",
        "      input_glovo = batch_x_g.to(device)\n",
        "      input_w2w = batch_x_w2w.to(device)\n",
        "\n",
        "\n",
        "\n",
        "      #print(batch_x.size())\n",
        "      model_glovo.eval()\n",
        "      model_w2w.eval()\n",
        "\n",
        "      prediction_lstm_glovo=model_glovo.forward(input_glovo)\n",
        "      prediction_lstm_w2w=model_w2w.forward(input_w2w)\n",
        "\n",
        "\n",
        "      prediction = model_classifier.forward(prediction_lstm_glovo,prediction_lstm_w2w)\n",
        "\n",
        "\n",
        "      sizes=prediction.size()\n",
        "      l0=sizes[0]\n",
        "      l1=sizes[1]\n",
        "      l2=sizes[2]\n",
        "      l3=l0*l1\n",
        "      new_size = (l3,l2)\n",
        "      prediction_batch = torch.reshape(prediction,new_size)\n",
        "      target_batch = torch.flatten(batch_y)\n",
        "      target_batch = target_batch.to(device)\n",
        "    \n",
        "\n",
        "      \n",
        "\n",
        "      loss = loss_function(prediction_batch,target_batch)\n",
        "      running_loss_val += loss.item()\n",
        "\n",
        "\n",
        "      pre_accu=torch.argmax(prediction_batch, dim=1)\n",
        "      pre_accu = pre_accu.to('cpu')\n",
        "      target_batch = target_batch.to('cpu')\n",
        "      \n",
        "      train_acc = torch.sum(pre_accu == target_batch)\n",
        "      batch_train_acc = (np.array(train_acc))/(target_batch.size())\n",
        "\n",
        "      accuracy_epoch_val=accuracy_epoch_val+batch_train_acc\n",
        "      \n",
        "\n",
        "      \n",
        "      total_prediction_val=total_prediction_val+(pre_accu.tolist())\n",
        "      total_labels_val=total_labels_val+(target_batch.tolist())\n",
        "\n",
        "    \n",
        "      \n",
        "      count_val+=1\n",
        "        \n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    running_loss_val_avg = (running_loss_val/count_val)\n",
        "    loss_history_val.append(running_loss_val_avg)\n",
        "    f1_score_epoch_val = f1_score(total_labels_val, total_prediction_val,average=None)\n",
        "    f1_score_epoch_val_macro = f1_score(total_labels_val, total_prediction_val,average='macro')\n",
        "    f1_history_val.append(f1_score_epoch_val_macro)\n",
        "    print('______________________VALIDATION_______________________________')\n",
        "    print('f1 score :',f1_score_epoch_val)\n",
        "    print('accuracy training :',accuracy_epoch_val/count_val)\n",
        "    print('f1 score macro: ',f1_score_epoch_val_macro)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "torch.save(model_classifier.state_dict(),'/content/drive/MyDrive/NLP/nlp2022-hw1-main/model/model_classifier.pt')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Okc9Nd5q_w54",
        "outputId": "afff8942-72d1-476b-9c3a-dfbe6cfdee5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EPOCHS n.0\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.9713276  0.00390016 0.00472813 0.36901099 0.24850205 0.43369694\n",
            " 0.         0.00475342 0.01315457 0.42480527 0.00408302 0.00433135\n",
            " 0.0027482 ]\n",
            "accuracy training : [0.90622726]\n",
            "f1 score macro:  0.1911570525935559\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.97808097 0.00819672 0.         0.53393665 0.71884058 0.78328982\n",
            " 0.         0.         0.         0.5876494  0.         0.\n",
            " 0.        ]\n",
            "accuracy training : [0.93026746]\n",
            "f1 score macro:  0.2776918572075572\n",
            "\n",
            "\n",
            "EPOCHS n.1\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.98800634 0.58227297 0.         0.69202824 0.79935467 0.89947427\n",
            " 0.         0.         0.4732965  0.71816809 0.         0.\n",
            " 0.23345289]\n",
            "accuracy training : [0.94890066]\n",
            "f1 score macro:  0.414311844462056\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98332822 0.6961326  0.         0.5993266  0.80792683 0.86217009\n",
            " 0.         0.         0.60784314 0.76030928 0.         0.\n",
            " 0.68      ]\n",
            "accuracy training : [0.94808511]\n",
            "f1 score macro:  0.4613105194596826\n",
            "\n",
            "\n",
            "EPOCHS n.2\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99146187 0.80825434 0.270027   0.78425173 0.86631494 0.94461999\n",
            " 0.         0.         0.71168015 0.84604212 0.         0.\n",
            " 0.8070543 ]\n",
            "accuracy training : [0.96268002]\n",
            "f1 score macro:  0.540746650617757\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98404004 0.76447876 0.45652174 0.65046729 0.84984026 0.86775632\n",
            " 0.         0.         0.63316583 0.77308707 0.         0.\n",
            " 0.71052632]\n",
            "accuracy training : [0.95171205]\n",
            "f1 score macro:  0.5146064324350133\n",
            "\n",
            "\n",
            "EPOCHS n.3\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99238614 0.85687866 0.6915263  0.85410926 0.9102504  0.95138947\n",
            " 0.         0.         0.75732858 0.8549752  0.         0.\n",
            " 0.82082324]\n",
            "accuracy training : [0.96780587]\n",
            "f1 score macro:  0.591512864545264\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98402948 0.78362573 0.48101266 0.65420561 0.85530547 0.87518355\n",
            " 0.         0.         0.64373464 0.77393617 0.         0.\n",
            " 0.71947195]\n",
            "accuracy training : [0.95220504]\n",
            "f1 score macro:  0.5208080970542954\n",
            "\n",
            "\n",
            "EPOCHS n.4\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.9929377  0.88456219 0.74734043 0.86456552 0.9307177  0.95817554\n",
            " 0.54256571 0.         0.82910852 0.86062028 0.         0.\n",
            " 0.83014313]\n",
            "accuracy training : [0.97139724]\n",
            "f1 score macro:  0.6492874395696767\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98435876 0.7854251  0.50429799 0.66921606 0.86178862 0.87315634\n",
            " 0.60150376 0.         0.70028011 0.77718833 0.         0.\n",
            " 0.70550162]\n",
            "accuracy training : [0.954981]\n",
            "f1 score macro:  0.5740551301137258\n",
            "\n",
            "\n",
            "EPOCHS n.5\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99350519 0.91836735 0.78055517 0.87970236 0.94884811 0.96143134\n",
            " 0.74216797 0.38191976 0.89157364 0.89853958 0.         0.\n",
            " 0.85353003]\n",
            "accuracy training : [0.9758439]\n",
            "f1 score macro:  0.7115492685840688\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98478431 0.80318091 0.53221289 0.6743295  0.87027915 0.88261516\n",
            " 0.64259928 0.60526316 0.70985915 0.81575246 0.         0.\n",
            " 0.76190476]\n",
            "accuracy training : [0.95818477]\n",
            "f1 score macro:  0.6371369787748348\n",
            "\n",
            "\n",
            "EPOCHS n.6\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99412857 0.92466506 0.79051712 0.90328064 0.95510761 0.97426691\n",
            " 0.78588882 0.82282004 0.90172884 0.95156789 0.         0.\n",
            " 0.91825821]\n",
            "accuracy training : [0.98036497]\n",
            "f1 score macro:  0.7632484387545257\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98476893 0.80885312 0.53757225 0.68359375 0.863711   0.88622754\n",
            " 0.65714286 0.63755459 0.73184358 0.81729428 0.         0.\n",
            " 0.75862069]\n",
            "accuracy training : [0.95888108]\n",
            "f1 score macro:  0.6436294300850203\n",
            "\n",
            "\n",
            "EPOCHS n.7\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99409502 0.92802989 0.79751209 0.90510204 0.95420369 0.97206322\n",
            " 0.80012329 0.8358528  0.91052233 0.95536891 0.         0.\n",
            " 0.92574919]\n",
            "accuracy training : [0.98076983]\n",
            "f1 score macro:  0.7675863435172671\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98469472 0.80645161 0.52957746 0.67061144 0.86970684 0.87964339\n",
            " 0.65201465 0.66945607 0.71910112 0.81398601 0.         0.\n",
            " 0.75958188]\n",
            "accuracy training : [0.95845224]\n",
            "f1 score macro:  0.6426788620165629\n",
            "\n",
            "\n",
            "EPOCHS n.8\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.9943123  0.93069742 0.80170283 0.90864281 0.95836191 0.97470085\n",
            " 0.80710349 0.84718826 0.9137931  0.9605976  0.         0.\n",
            " 0.93091603]\n",
            "accuracy training : [0.98139361]\n",
            "f1 score macro:  0.7713858935634725\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98479438 0.8040404  0.53025937 0.68379447 0.86699507 0.88656716\n",
            " 0.66428571 0.67226891 0.72067039 0.80796586 0.         0.\n",
            " 0.75254237]\n",
            "accuracy training : [0.95876052]\n",
            "f1 score macro:  0.6441680078576493\n",
            "\n",
            "\n",
            "EPOCHS n.9\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99433323 0.93186044 0.81154218 0.91063541 0.95594282 0.97598085\n",
            " 0.80036883 0.84647176 0.91136569 0.95933093 0.         0.\n",
            " 0.93637227]\n",
            "accuracy training : [0.98146904]\n",
            "f1 score macro:  0.7718618781494974\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98478647 0.80318091 0.54131054 0.67710372 0.86743044 0.8820059\n",
            " 0.65942029 0.66115702 0.72521246 0.80965909 0.         0.\n",
            " 0.76870748]\n",
            "accuracy training : [0.95867841]\n",
            "f1 score macro:  0.6446134103930699\n",
            "\n",
            "\n",
            "EPOCHS n.10\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.9943697  0.92885289 0.80440696 0.91235878 0.95564005 0.9746349\n",
            " 0.80547529 0.84530725 0.91262428 0.96366172 0.         0.\n",
            " 0.93488195]\n",
            "accuracy training : [0.98147963]\n",
            "f1 score macro:  0.7717087511517141\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98465982 0.81287726 0.54794521 0.671875   0.87254902 0.88095238\n",
            " 0.66431095 0.65833333 0.73537604 0.81388889 0.         0.\n",
            " 0.76923077]\n",
            "accuracy training : [0.95867286]\n",
            "f1 score macro:  0.6470768213038084\n",
            "\n",
            "\n",
            "EPOCHS n.11\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99450326 0.93361178 0.81399177 0.91658873 0.96106437 0.97783862\n",
            " 0.80139796 0.85819408 0.91686675 0.96320577 0.         0.\n",
            " 0.93631539]\n",
            "accuracy training : [0.98199073]\n",
            "f1 score macro:  0.774890652382082\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98483666 0.81037924 0.54857143 0.6798419  0.87540984 0.88955224\n",
            " 0.65467626 0.66666667 0.74157303 0.81481481 0.         0.\n",
            " 0.76056338]\n",
            "accuracy training : [0.9593272]\n",
            "f1 score macro:  0.6482219579711376\n",
            "\n",
            "\n",
            "EPOCHS n.12\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99442798 0.9337581  0.80819113 0.91218806 0.96154975 0.97621899\n",
            " 0.81678922 0.86341314 0.91924347 0.96329145 0.         0.\n",
            " 0.93715377]\n",
            "accuracy training : [0.98198402]\n",
            "f1 score macro:  0.775863466039958\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98487108 0.80314961 0.55585831 0.6719057  0.87314662 0.88592593\n",
            " 0.64808362 0.67782427 0.72676056 0.80905233 0.         0.\n",
            " 0.76094276]\n",
            "accuracy training : [0.95866607]\n",
            "f1 score macro:  0.6459631382484853\n",
            "\n",
            "\n",
            "EPOCHS n.13\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99451931 0.93238512 0.818517   0.91052632 0.9601251  0.97563894\n",
            " 0.81261482 0.86593475 0.91873216 0.96200459 0.         0.\n",
            " 0.9345193 ]\n",
            "accuracy training : [0.98202985]\n",
            "f1 score macro:  0.7758090312645644\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98509299 0.80885312 0.56198347 0.67460317 0.87397709 0.88921713\n",
            " 0.66666667 0.68421053 0.73389356 0.81388889 0.         0.\n",
            " 0.76655052]\n",
            "accuracy training : [0.95956073]\n",
            "f1 score macro:  0.6506874722178116\n",
            "\n",
            "\n",
            "EPOCHS n.14\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99450926 0.93318729 0.81818182 0.91656056 0.96036615 0.9779374\n",
            " 0.82145034 0.86275116 0.91908122 0.96549458 0.         0.\n",
            " 0.94099791]\n",
            "accuracy training : [0.98227488]\n",
            "f1 score macro:  0.7777321304220355\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98480186 0.80730223 0.55401662 0.67698259 0.87458746 0.88757396\n",
            " 0.66197183 0.68085106 0.73278237 0.81337047 0.         0.\n",
            " 0.75085324]\n",
            "accuracy training : [0.958921]\n",
            "f1 score macro:  0.6480841309729171\n",
            "\n",
            "\n",
            "EPOCHS n.15\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99443911 0.93380173 0.81829419 0.91316193 0.96012479 0.97492083\n",
            " 0.82309469 0.86801719 0.91645418 0.96534735 0.         0.\n",
            " 0.94070847]\n",
            "accuracy training : [0.98219215]\n",
            "f1 score macro:  0.7775664959156605\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98487968 0.80482897 0.5698324  0.68615984 0.86985173 0.88461538\n",
            " 0.65949821 0.67811159 0.73595506 0.81223922 0.         0.\n",
            " 0.75432526]\n",
            "accuracy training : [0.95919626]\n",
            "f1 score macro:  0.6492536418128995\n",
            "\n",
            "\n",
            "EPOCHS n.16\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.9944936  0.9367338  0.81720137 0.91348535 0.95928132 0.97671245\n",
            " 0.82781863 0.87094782 0.91737892 0.96617961 0.         0.\n",
            " 0.94077449]\n",
            "accuracy training : [0.98234964]\n",
            "f1 score macro:  0.7785390270375601\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98487108 0.81526104 0.56666667 0.6756238  0.8762215  0.88659794\n",
            " 0.65734266 0.67782427 0.73389356 0.81126761 0.         0.\n",
            " 0.7804878 ]\n",
            "accuracy training : [0.95925876]\n",
            "f1 score macro:  0.6512352250305307\n",
            "\n",
            "\n",
            "EPOCHS n.17\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99455633 0.93786918 0.82050585 0.91749401 0.96044536 0.97750406\n",
            " 0.82184174 0.86826716 0.91985538 0.96422124 0.         0.\n",
            " 0.93676638]\n",
            "accuracy training : [0.98240629]\n",
            "f1 score macro:  0.7784097436574849\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98504142 0.81262327 0.55737705 0.6746507  0.87272727 0.88757396\n",
            " 0.65248227 0.67213115 0.72222222 0.81073446 0.         0.\n",
            " 0.77508651]\n",
            "accuracy training : [0.95910747]\n",
            "f1 score macro:  0.6478961759247243\n",
            "\n",
            "\n",
            "EPOCHS n.18\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99454922 0.93343518 0.82647099 0.9190712  0.96028881 0.97506213\n",
            " 0.82275778 0.86895068 0.92081142 0.96592032 0.         0.\n",
            " 0.93645107]\n",
            "accuracy training : [0.98243351]\n",
            "f1 score macro:  0.7787514453533549\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98518834 0.81262327 0.57223796 0.6812749  0.87581699 0.88296296\n",
            " 0.65724382 0.69198312 0.72268908 0.81586402 0.         0.\n",
            " 0.76712329]\n",
            "accuracy training : [0.95968796]\n",
            "f1 score macro:  0.6511544427590091\n",
            "\n",
            "\n",
            "EPOCHS n.19\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99449578 0.93640231 0.82155525 0.91812468 0.96236191 0.97718144\n",
            " 0.82578665 0.87687781 0.91718022 0.96388114 0.         0.\n",
            " 0.93864452]\n",
            "accuracy training : [0.98245344]\n",
            "f1 score macro:  0.7794224384199578\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98497148 0.80730223 0.56353591 0.6798419  0.87438825 0.89349112\n",
            " 0.65248227 0.67206478 0.73033708 0.81638418 0.         0.\n",
            " 0.76712329]\n",
            "accuracy training : [0.95932316]\n",
            "f1 score macro:  0.6493786533907322\n",
            "\n",
            "\n",
            "EPOCHS n.20\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99451293 0.93374019 0.82246327 0.91639652 0.9619783  0.97837422\n",
            " 0.82905719 0.87811677 0.92344569 0.96587367 0.         0.\n",
            " 0.94242827]\n",
            "accuracy training : [0.98258541]\n",
            "f1 score macro:  0.780491309557616\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98502449 0.80079681 0.56410256 0.67741935 0.87070376 0.89185185\n",
            " 0.64788732 0.6835443  0.72876712 0.82319661 0.         0.\n",
            " 0.7766323 ]\n",
            "accuracy training : [0.95955834]\n",
            "f1 score macro:  0.6499943455924608\n",
            "\n",
            "\n",
            "EPOCHS n.21\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99455751 0.93410304 0.82628852 0.92037671 0.9632669  0.98102841\n",
            " 0.83104459 0.87561728 0.92344426 0.96478122 0.         0.\n",
            " 0.93961764]\n",
            "accuracy training : [0.98271852]\n",
            "f1 score macro:  0.7810866225585806\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98488111 0.8015873  0.55462185 0.67474747 0.87254902 0.88954345\n",
            " 0.65734266 0.68907563 0.72423398 0.81081081 0.         0.\n",
            " 0.77931034]\n",
            "accuracy training : [0.95916736]\n",
            "f1 score macro:  0.6491310480573722\n",
            "\n",
            "\n",
            "EPOCHS n.22\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99460572 0.9332465  0.83276636 0.91782102 0.96611829 0.9795709\n",
            " 0.82272312 0.8739781  0.92555271 0.96699156 0.         0.\n",
            " 0.93982267]\n",
            "accuracy training : [0.98271346]\n",
            "f1 score macro:  0.7810151520090167\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98461174 0.7959596  0.54495913 0.67063492 0.87278583 0.88888889\n",
            " 0.65703971 0.6779661  0.72980501 0.80939227 0.         0.\n",
            " 0.77241379]\n",
            "accuracy training : [0.95850989]\n",
            "f1 score macro:  0.6464966915685582\n",
            "\n",
            "\n",
            "EPOCHS n.23\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99461248 0.93771777 0.82600382 0.92109748 0.96386719 0.9803888\n",
            " 0.83384997 0.87633493 0.92226574 0.96565325 0.         0.\n",
            " 0.94042232]\n",
            "accuracy training : [0.98285431]\n",
            "f1 score macro:  0.7817087502530319\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98492201 0.80318091 0.55955679 0.66933868 0.87438825 0.88988095\n",
            " 0.65714286 0.68085106 0.73537604 0.81327801 0.         0.\n",
            " 0.77027027]\n",
            "accuracy training : [0.95916311]\n",
            "f1 score macro:  0.6490912181418876\n",
            "\n",
            "\n",
            "EPOCHS n.24\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.994522   0.93643883 0.83092051 0.91634142 0.96299922 0.9790378\n",
            " 0.83318001 0.87631742 0.92219886 0.96647816 0.         0.\n",
            " 0.93920572]\n",
            "accuracy training : [0.98268633]\n",
            "f1 score macro:  0.7813569189896197\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98467288 0.808      0.55555556 0.67583497 0.87666667 0.89285714\n",
            " 0.65703971 0.68085106 0.71751412 0.8056338  0.         0.\n",
            " 0.77133106]\n",
            "accuracy training : [0.95893368]\n",
            "f1 score macro:  0.6481505365595314\n",
            "\n",
            "\n",
            "EPOCHS n.25\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99465632 0.93914564 0.83220922 0.92077856 0.96346943 0.98119365\n",
            " 0.83055258 0.87442004 0.92293826 0.96742965 0.         0.\n",
            " 0.94422386]\n",
            "accuracy training : [0.98298451]\n",
            "f1 score macro:  0.7823859387449328\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98477494 0.80876494 0.55466667 0.67322835 0.875      0.88757396\n",
            " 0.65480427 0.66666667 0.72676056 0.80609418 0.         0.\n",
            " 0.77777778]\n",
            "accuracy training : [0.95868752]\n",
            "f1 score macro:  0.6473932552308468\n",
            "\n",
            "\n",
            "EPOCHS n.26\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99466366 0.93541348 0.82578539 0.91531745 0.96638244 0.97998289\n",
            " 0.82795865 0.88094871 0.92243187 0.9653591  0.         0.\n",
            " 0.94059781]\n",
            "accuracy training : [0.98279617]\n",
            "f1 score macro:  0.7811416501354997\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.9850174  0.808      0.56198347 0.67326733 0.87520259 0.88888889\n",
            " 0.66202091 0.68669528 0.72928177 0.8079096  0.         0.\n",
            " 0.77508651]\n",
            "accuracy training : [0.95924381]\n",
            "f1 score macro:  0.6502579799468818\n",
            "\n",
            "\n",
            "EPOCHS n.27\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99462374 0.93645267 0.82598608 0.92079208 0.96332518 0.9780248\n",
            " 0.82360097 0.87652604 0.92758413 0.96669401 0.         0.\n",
            " 0.93456187]\n",
            "accuracy training : [0.98271641]\n",
            "f1 score macro:  0.7806285818922174\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98508028 0.80792079 0.5606469  0.67334669 0.87987013 0.88529412\n",
            " 0.65       0.66666667 0.73389356 0.80721221 0.         0.\n",
            " 0.77133106]\n",
            "accuracy training : [0.95904614]\n",
            "f1 score macro:  0.6477894156095242\n",
            "\n",
            "\n",
            "EPOCHS n.28\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99454614 0.93510195 0.82942779 0.91678012 0.96591577 0.98023783\n",
            " 0.81892879 0.88055034 0.92430159 0.96598192 0.         0.\n",
            " 0.93909774]\n",
            "accuracy training : [0.98267339]\n",
            "f1 score macro:  0.7808361537705854\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98488182 0.81059063 0.56267409 0.67203219 0.87908497 0.88988095\n",
            " 0.66666667 0.6893617  0.72727273 0.80337079 0.         0.\n",
            " 0.77288136]\n",
            "accuracy training : [0.95929073]\n",
            "f1 score macro:  0.6506690692420709\n",
            "\n",
            "\n",
            "EPOCHS n.29\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99456247 0.93636066 0.82125473 0.91750913 0.96509804 0.98044907\n",
            " 0.83555693 0.88038726 0.920434   0.97022394 0.         0.\n",
            " 0.94368859]\n",
            "accuracy training : [0.98281213]\n",
            "f1 score macro:  0.7819634474077262\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98508876 0.80561122 0.55211268 0.67857143 0.87987013 0.88888889\n",
            " 0.66428571 0.68376068 0.73684211 0.81512605 0.         0.\n",
            " 0.7766323 ]\n",
            "accuracy training : [0.95960812]\n",
            "f1 score macro:  0.651291535335642\n",
            "\n",
            "\n",
            "EPOCHS n.30\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.9944333  0.93534389 0.83097826 0.91829926 0.9657266  0.97987841\n",
            " 0.83851028 0.88616737 0.92376951 0.96569834 0.         0.\n",
            " 0.93511882]\n",
            "accuracy training : [0.98277166]\n",
            "f1 score macro:  0.7826095417676788\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98488969 0.80487805 0.56497175 0.68008048 0.87702265 0.88724036\n",
            " 0.66181818 0.67510549 0.72881356 0.80959097 0.         0.\n",
            " 0.76124567]\n",
            "accuracy training : [0.95935433]\n",
            "f1 score macro:  0.6488966811411656\n",
            "\n",
            "\n",
            "EPOCHS n.31\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99459451 0.93490094 0.83507818 0.91898799 0.96630094 0.98083176\n",
            " 0.82881226 0.87668266 0.92409241 0.96891659 0.         0.\n",
            " 0.93913375]\n",
            "accuracy training : [0.98288784]\n",
            "f1 score macro:  0.7821793839432825\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98494247 0.81656805 0.55462185 0.67729084 0.88235294 0.88592593\n",
            " 0.65100671 0.67219917 0.72176309 0.81241185 0.         0.\n",
            " 0.78321678]\n",
            "accuracy training : [0.95916017]\n",
            "f1 score macro:  0.6494076666555648\n",
            "\n",
            "\n",
            "EPOCHS n.32\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99467384 0.93761568 0.83118294 0.92479536 0.96636925 0.97973146\n",
            " 0.82641108 0.8724687  0.92743628 0.96677632 0.         0.\n",
            " 0.93908437]\n",
            "accuracy training : [0.98295634]\n",
            "f1 score macro:  0.7820419444690454\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98480689 0.80894309 0.56111111 0.68359375 0.87662338 0.88888889\n",
            " 0.66903915 0.69230769 0.72268908 0.81065919 0.         0.\n",
            " 0.76712329]\n",
            "accuracy training : [0.95927909]\n",
            "f1 score macro:  0.6512142688796713\n",
            "\n",
            "\n",
            "EPOCHS n.33\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99461576 0.93689373 0.83063409 0.92072963 0.96580696 0.98141964\n",
            " 0.83295054 0.8811037  0.9270567  0.9696771  0.         0.\n",
            " 0.9439006 ]\n",
            "accuracy training : [0.98304463]\n",
            "f1 score macro:  0.7834452663631974\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98457681 0.80161943 0.55172414 0.67864271 0.87828947 0.88855869\n",
            " 0.66431095 0.66393443 0.71666667 0.81012658 0.         0.\n",
            " 0.7739726 ]\n",
            "accuracy training : [0.95877956]\n",
            "f1 score macro:  0.6471094224788183\n",
            "\n",
            "\n",
            "EPOCHS n.34\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99463865 0.93825547 0.83457526 0.92186967 0.96397807 0.97681581\n",
            " 0.82704931 0.87987664 0.9242515  0.96487773 0.         0.\n",
            " 0.94255924]\n",
            "accuracy training : [0.9828804]\n",
            "f1 score macro:  0.7822113344181493\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98493057 0.80478088 0.54901961 0.68016194 0.8776509  0.88955224\n",
            " 0.6618705  0.68376068 0.73743017 0.8178025  0.         0.\n",
            " 0.76712329]\n",
            "accuracy training : [0.95950887]\n",
            "f1 score macro:  0.6503140982191543\n",
            "\n",
            "\n",
            "EPOCHS n.35\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99466215 0.93625368 0.83950954 0.92365564 0.96677448 0.97877439\n",
            " 0.82776506 0.88072252 0.92830302 0.96818219 0.         0.\n",
            " 0.93980436]\n",
            "accuracy training : [0.9830863]\n",
            "f1 score macro:  0.783415925337512\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98485207 0.80792079 0.56509695 0.67710372 0.87725041 0.88659794\n",
            " 0.6618705  0.68695652 0.73184358 0.81678322 0.         0.\n",
            " 0.77241379]\n",
            "accuracy training : [0.95938122]\n",
            "f1 score macro:  0.6514376532419128\n",
            "\n",
            "\n",
            "EPOCHS n.36\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99452354 0.93816678 0.83678474 0.92194956 0.96564549 0.98121905\n",
            " 0.83529953 0.87839727 0.92924741 0.96794872 0.         0.\n",
            " 0.93796244]\n",
            "accuracy training : [0.98299379]\n",
            "f1 score macro:  0.7836265007677632\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98464378 0.80555556 0.56657224 0.67953668 0.8776509  0.89387145\n",
            " 0.66428571 0.68333333 0.72413793 0.81284916 0.         0.\n",
            " 0.76760563]\n",
            "accuracy training : [0.95919526]\n",
            "f1 score macro:  0.6507724902244506\n",
            "\n",
            "\n",
            "EPOCHS n.37\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99469941 0.93566872 0.83826134 0.92165741 0.96723075 0.98154982\n",
            " 0.8309253  0.87891538 0.92648388 0.97030353 0.         0.\n",
            " 0.94159759]\n",
            "accuracy training : [0.98317469]\n",
            "f1 score macro:  0.7836379332180697\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98464596 0.80321285 0.55826558 0.6745098  0.88196721 0.88921713\n",
            " 0.65942029 0.68995633 0.72       0.81741573 0.         0.\n",
            " 0.77083333]\n",
            "accuracy training : [0.95911225]\n",
            "f1 score macro:  0.6499572483806335\n",
            "\n",
            "\n",
            "EPOCHS n.38\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99469053 0.93502825 0.82795115 0.91784218 0.96586227 0.98048947\n",
            " 0.83035578 0.88108614 0.92943305 0.96909076 0.         0.\n",
            " 0.93488897]\n",
            "accuracy training : [0.98294813]\n",
            "f1 score macro:  0.7820552746902817\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98488611 0.80487805 0.55718475 0.68349515 0.8852459  0.89088191\n",
            " 0.66666667 0.68644068 0.73537604 0.81626928 0.         0.\n",
            " 0.76510067]\n",
            "accuracy training : [0.95967859]\n",
            "f1 score macro:  0.6520327091396434\n",
            "\n",
            "\n",
            "EPOCHS n.39\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99473906 0.9387977  0.83689108 0.919847   0.96798198 0.98036862\n",
            " 0.83328216 0.88482406 0.92487279 0.97109446 0.         0.\n",
            " 0.94438181]\n",
            "accuracy training : [0.98325722]\n",
            "f1 score macro:  0.7843908250436166\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.9845877  0.80157171 0.55890411 0.67052023 0.87987013 0.88989442\n",
            " 0.66666667 0.69827586 0.74114441 0.81843575 0.         0.\n",
            " 0.76124567]\n",
            "accuracy training : [0.95902086]\n",
            "f1 score macro:  0.6516243595657991\n",
            "\n",
            "\n",
            "EPOCHS n.40\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99463289 0.93808386 0.83119366 0.92007105 0.96820894 0.97961631\n",
            " 0.83772066 0.8846393  0.93042047 0.96660086 0.         0.\n",
            " 0.9406015 ]\n",
            "accuracy training : [0.98309911]\n",
            "f1 score macro:  0.7839838077494942\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98460301 0.80894309 0.55840456 0.67594433 0.8762215  0.88690476\n",
            " 0.66423358 0.6893617  0.73333333 0.81276006 0.         0.\n",
            " 0.77192982]\n",
            "accuracy training : [0.95923667]\n",
            "f1 score macro:  0.6509722882634288\n",
            "\n",
            "\n",
            "EPOCHS n.41\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99460955 0.94126604 0.83493829 0.92380056 0.96481626 0.98032506\n",
            " 0.82730188 0.88507719 0.92620482 0.96718622 0.         0.\n",
            " 0.94351782]\n",
            "accuracy training : [0.98306864]\n",
            "f1 score macro:  0.7837725914738646\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98472669 0.81466395 0.5648415  0.68787276 0.87804878 0.89020772\n",
            " 0.64705882 0.67226891 0.73142857 0.81346424 0.         0.\n",
            " 0.77508651]\n",
            "accuracy training : [0.95956634]\n",
            "f1 score macro:  0.6507437261660306\n",
            "\n",
            "\n",
            "EPOCHS n.42\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99455604 0.9377042  0.83631399 0.91595636 0.96683023 0.97978678\n",
            " 0.82691429 0.8834799  0.92398013 0.96849877 0.         0.\n",
            " 0.94750706]\n",
            "accuracy training : [0.98294176]\n",
            "f1 score macro:  0.7831944424272229\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98497859 0.8040404  0.56582633 0.68389662 0.8830313  0.89153046\n",
            " 0.66197183 0.68103448 0.73684211 0.81346424 0.         0.\n",
            " 0.76551724]\n",
            "accuracy training : [0.95963968]\n",
            "f1 score macro:  0.6517025849619089\n",
            "\n",
            "\n",
            "EPOCHS n.43\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99470812 0.94023213 0.84480174 0.91862937 0.96692112 0.98125161\n",
            " 0.82456406 0.88312898 0.92677071 0.9696076  0.         0.\n",
            " 0.94348894]\n",
            "accuracy training : [0.98318724]\n",
            "f1 score macro:  0.7841618758092049\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98506615 0.804      0.56657224 0.68379447 0.87378641 0.89020772\n",
            " 0.67132867 0.68376068 0.73333333 0.81843575 0.         0.\n",
            " 0.77083333]\n",
            "accuracy training : [0.95969147]\n",
            "f1 score macro:  0.6523937501814742\n",
            "\n",
            "\n",
            "EPOCHS n.44\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.9946346  0.93884657 0.84368132 0.92226299 0.96417384 0.97897436\n",
            " 0.83109346 0.8834604  0.92671253 0.9698414  0.         0.\n",
            " 0.93975449]\n",
            "accuracy training : [0.98313377]\n",
            "f1 score macro:  0.7841104594826304\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98494054 0.812      0.56160458 0.68674699 0.88091354 0.89285714\n",
            " 0.66423358 0.67811159 0.73033708 0.8180536  0.         0.\n",
            " 0.77192982]\n",
            "accuracy training : [0.9599316]\n",
            "f1 score macro:  0.6524406509297199\n",
            "\n",
            "\n",
            "EPOCHS n.45\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99462693 0.93963368 0.84168937 0.92184437 0.96605693 0.98142282\n",
            " 0.82600733 0.88906226 0.9251353  0.97191798 0.         0.\n",
            " 0.94226415]\n",
            "accuracy training : [0.98319449]\n",
            "f1 score macro:  0.784589316530636\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98469545 0.81451613 0.57060519 0.67809524 0.87868852 0.88659794\n",
            " 0.65934066 0.6835443  0.73239437 0.8180536  0.         0.\n",
            " 0.77304965]\n",
            "accuracy training : [0.9594653]\n",
            "f1 score macro:  0.6522754642310444\n",
            "\n",
            "\n",
            "EPOCHS n.46\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99472482 0.93823944 0.83462638 0.92027142 0.96709948 0.98044573\n",
            " 0.83320546 0.88777743 0.9287218  0.96796978 0.         0.\n",
            " 0.93846735]\n",
            "accuracy training : [0.98318902]\n",
            "f1 score macro:  0.7839653150827322\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98490084 0.81048387 0.56824513 0.68359375 0.8762215  0.89217134\n",
            " 0.64981949 0.68669528 0.73802817 0.8137931  0.         0.\n",
            " 0.77622378]\n",
            "accuracy training : [0.95955252]\n",
            "f1 score macro:  0.6523212499141646\n",
            "\n",
            "\n",
            "EPOCHS n.47\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99460578 0.93877107 0.83913221 0.91810528 0.96532757 0.97946963\n",
            " 0.83691838 0.88791484 0.92922615 0.96687982 0.         0.\n",
            " 0.9466541 ]\n",
            "accuracy training : [0.98309891]\n",
            "f1 score macro:  0.7848465254384936\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98471874 0.81147541 0.56666667 0.68514851 0.8776509  0.89355322\n",
            " 0.65467626 0.68669528 0.7394958  0.80601093 0.         0.\n",
            " 0.76156584]\n",
            "accuracy training : [0.95935964]\n",
            "f1 score macro:  0.6513582733202229\n",
            "\n",
            "\n",
            "EPOCHS n.48\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.9945797  0.93691538 0.84096451 0.92152505 0.9705767  0.98108686\n",
            " 0.83226398 0.8865625  0.92729189 0.96769433 0.         0.\n",
            " 0.94379479]\n",
            "accuracy training : [0.98316234]\n",
            "f1 score macro:  0.7848658212044322\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98495316 0.81376518 0.55462185 0.68525896 0.87356322 0.88659794\n",
            " 0.66666667 0.68085106 0.73684211 0.81553398 0.         0.\n",
            " 0.77622378]\n",
            "accuracy training : [0.95959926]\n",
            "f1 score macro:  0.6519136846324665\n",
            "\n",
            "\n",
            "EPOCHS n.49\n",
            "______________________TRAIN_______________________________\n",
            "f1 score : [0.99479824 0.93708717 0.83688136 0.92469083 0.96762166 0.98185553\n",
            " 0.82999235 0.88681302 0.92957746 0.96946877 0.         0.\n",
            " 0.94075472]\n",
            "accuracy training : [0.98335038]\n",
            "f1 score macro:  0.7845800848917727\n",
            "______________________VALIDATION_______________________________\n",
            "f1 score : [0.98476172 0.80722892 0.56756757 0.68379447 0.88052373 0.88855869\n",
            " 0.66423358 0.67811159 0.73087819 0.81729428 0.         0.\n",
            " 0.7628866 ]\n",
            "accuracy training : [0.95937179]\n",
            "f1 score macro:  0.6512184099527025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uRpJ0wM5dLO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_classifier.parameters(), lr=0.1, momentum=0.9)\n",
        "emb_glove = Custom_Embedding(weight_tensor_glove,Dictionary_glove,True,True)\n",
        "emb_w2w = Custom_Embedding(weight_tensor_w2w,Dictionary_w2w2,True,True)\n",
        "\n",
        "\n",
        "i=0\n",
        "loss_history = []\n",
        "loss_history_val = []\n",
        "\n",
        "\n",
        "f1_history = []\n",
        "f1_history_val = []\n",
        "\n",
        "for epoch in range(50):\n",
        "\n",
        "  count=0\n",
        "  accuracy_epoch=0\n",
        "  total_prediction=[]\n",
        "  total_labels=[]\n",
        "  running_loss = 0\n",
        "  model_classifier.train()\n",
        "  \n",
        "\n",
        "  for ext_counter,batch in enumerate(train_data_loader_glove):\n",
        "    for in_counter,batch_ in enumerate(train_data_loader_w2w):\n",
        "      \n",
        "\n",
        "\n",
        "      if(ext_counter==in_counter):\n",
        "\n",
        "        model_classifier.zero_grad()\n",
        "\n",
        "        batch_x_g = batch['x']\n",
        "        batch_x_w2w = batch_['x']\n",
        "\n",
        "        \n",
        "        batch_y = batch['y']\n",
        "        #or is the same\n",
        "        #batch_y = batch_['y']\n",
        "\n",
        "        #GLOVE EMBEDDING\n",
        "        batch_x_g = emb_glove.embedd(batch_x_g.tolist())\n",
        "        batch_x_w2w = emb_w2w.embedd(batch_x_w2w.tolist())\n",
        "        #print(batch_x.size())\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        input_glovo = batch_x_g.to(device)\n",
        "        input_w2w = batch_x_w2w.to(device)\n",
        "\n",
        "        prediction_lstm_glovo=model_glovo.forward(input_glovo)\n",
        "        prediction_lstm_w2w=model_w2w.forward(input_w2w)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        prediction = model_classifier.forward(prediction_lstm_glovo,prediction_lstm_w2w)\n",
        "\n",
        "        #print('Predicted: ',prediction.size())\n",
        "        #print('Ground Truth: ',batch_y.size())\n",
        "        sizes=prediction.size()\n",
        "        #print(sizes[0])\n",
        "        l0=sizes[0]\n",
        "        l1=sizes[1]\n",
        "        l2=sizes[2]\n",
        "        l3=l0*l1\n",
        "\n",
        "        new_size = (l3,l2)\n",
        "        prediction_batch = torch.reshape(prediction,new_size)\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "        target_batch = torch.flatten(batch_y)\n",
        "        target_batch = target_batch.to(device)\n",
        "       \n",
        "\n",
        "      \n",
        "\n",
        "        \n",
        "\n",
        "        loss = loss_function(prediction_batch,target_batch)\n",
        "        running_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "        pre_accu=torch.argmax(prediction_batch, dim=1)\n",
        "        pre_accu = pre_accu.to('cpu')\n",
        "        target_batch = target_batch.to('cpu')\n",
        "     \n",
        "\n",
        "\n",
        "\n",
        "        #print('predited',pre_accu)\n",
        "        #print('target',target_batch)\n",
        "\n",
        "\n",
        "        train_acc = torch.sum(pre_accu == target_batch)\n",
        "\n",
        "\n",
        "        batch_train_acc = (np.array(train_acc))/(target_batch.size())\n",
        "\n",
        "        accuracy_epoch=accuracy_epoch+batch_train_acc\n",
        "        \n",
        "\n",
        "        \n",
        "        total_prediction=total_prediction+(pre_accu.tolist())\n",
        "        total_labels=total_labels+(target_batch.tolist())\n",
        "        count+=1\n",
        "\n",
        "\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "  \n",
        "\n",
        "  running_loss_avg = (running_loss/count)\n",
        "  loss_history.append(running_loss_avg)\n",
        "  f1_score_epoch = f1_score(total_labels, total_prediction,average=None)\n",
        "  f1_score_epoch_macro = f1_score(total_labels, total_prediction,average='macro')\n",
        "  f1_history.append(f1_score_epoch_macro)\n",
        "  print('\\n\\nEPOCHS n.'+str(epoch))\n",
        "  print('______________________TRAIN_______________________________')\n",
        "  print('f1 score :',f1_score_epoch)\n",
        "  print('accuracy training :',accuracy_epoch/count)\n",
        "  print('f1 score macro: ',f1_score_epoch_macro)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  '''\n",
        "  validation on this epoch\n",
        "  \n",
        "  '''\n",
        "  model_classifier.eval()\n",
        "  with torch.no_grad():\n",
        "\n",
        "    count_val=0\n",
        "    accuracy_epoch_val=0\n",
        "    total_prediction_val=[]\n",
        "    total_labels_val=[]\n",
        "    running_loss_val = 0\n",
        "\n",
        "    for ext_counter,batch in enumerate(train_data_loader_glove):\n",
        "      for in_counter,batch_ in enumerate(train_data_loader_w2w):\n",
        "      \n",
        "\n",
        "\n",
        "        if(ext_counter==in_counter):\n",
        "\n",
        "\n",
        "          batch_x_g = batch['x']\n",
        "          batch_x_w2w = batch_['x']\n",
        "\n",
        "          \n",
        "          batch_y = batch['y']\n",
        "          #or is the same\n",
        "          #batch_y = batch_['y']\n",
        "\n",
        "          #GLOVE EMBEDDING\n",
        "          batch_x_g = emb_glove.embedd(batch_x_g.tolist())\n",
        "          batch_x_w2w = emb_w2w.embedd(batch_x_w2w.tolist())\n",
        "          input_glovo = batch_x_g.to(device)\n",
        "          input_w2w = batch_x_w2w.to(device)\n",
        "          #print(batch_x.size())\n",
        "\n",
        "          \n",
        "          \n",
        "          \n",
        "\n",
        "          prediction_lstm_glovo=model_glovo.forward(input_glovo)\n",
        "          prediction_lstm_w2w=model_w2w.forward(input_w2w)\n",
        "\n",
        "\n",
        "          prediction = model_classifier.forward(prediction_lstm_glovo,prediction_lstm_w2w)\n",
        "\n",
        "\n",
        "          sizes=prediction.size()\n",
        "          l0=sizes[0]\n",
        "          l1=sizes[1]\n",
        "          l2=sizes[2]\n",
        "          l3=l0*l1\n",
        "          new_size = (l3,l2)\n",
        "          prediction_batch = torch.reshape(prediction,new_size)\n",
        "          target_batch = torch.flatten(batch_y)\n",
        "          target_batch = target_batch.to(device)\n",
        "        \n",
        "\n",
        "          \n",
        "\n",
        "          loss = loss_function(prediction_batch,target_batch)\n",
        "          running_loss_val += loss.item()\n",
        "\n",
        "\n",
        "          pre_accu=torch.argmax(prediction_batch, dim=1)\n",
        "          pre_accu = pre_accu.to('cpu')\n",
        "          target_batch = target_batch.to('cpu')\n",
        "          \n",
        "          train_acc = torch.sum(pre_accu == target_batch)\n",
        "          batch_train_acc = (np.array(train_acc))/(target_batch.size())\n",
        "\n",
        "          accuracy_epoch_val=accuracy_epoch_val+batch_train_acc\n",
        "          \n",
        "\n",
        "          \n",
        "          total_prediction_val=total_prediction_val+(pre_accu.tolist())\n",
        "          total_labels_val=total_labels_val+(target_batch.tolist())\n",
        "\n",
        "        \n",
        "          \n",
        "          count_val+=1\n",
        "        \n",
        "\n",
        "        else:\n",
        "          pass\n",
        "    \n",
        "\n",
        "    running_loss_val_avg = (running_loss_val/count_val)\n",
        "    loss_history_val.append(running_loss_val_avg)\n",
        "    f1_score_epoch_val = f1_score(total_labels_val, total_prediction_val,average=None)\n",
        "    f1_score_epoch_val_macro = f1_score(total_labels_val, total_prediction_val,average='macro')\n",
        "    f1_history_val.append(f1_score_epoch_val_macro)\n",
        "    print('______________________VALIDATION_______________________________')\n",
        "    print('f1 score :',f1_score_epoch_val)\n",
        "    print('accuracy training :',accuracy_epoch_val/count_val)\n",
        "    print('f1 score macro: ',f1_score_epoch_val_macro)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "torch.save(model_classifier.state_dict(),'/content/drive/MyDrive/NLP/nlp2022-hw1-main/model/model_classifier.pt')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/drive/MyDrive/NLP/nlp2022-hw1-main/model/model_classifier.pt')"
      ],
      "metadata": {
        "id": "rHeVjLFxOVS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRYgf7w65dLQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "c93268e6-002a-4230-bdb4-c87122f3f10e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#Plot accuracy\n",
        "#NB: my accuracy is \"drogata\" dalla presenza del padding \n",
        "#Padding elements are classified as 0,  class 0 is then more populated and because is accuracy is always above 0.9 tha final accuracy results more high then reality\n",
        "#In order to check is the model is Overfitting and limit the effect of padding on loss/accuracy results i am using the f_1 results on both train and \n",
        "plt.figure()\n",
        "\n",
        "plt.subplot(111)\n",
        "plt.title('Loss Evolution')\n",
        "plt.plot(np.array(loss_history), 'r',np.array(loss_history_val),'b')\n",
        "plt.ylabel('CE LOSS')\n",
        "plt.xlabel('Epochs')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(111)\n",
        "plt.title('F1 Evolution')\n",
        "plt.plot(np.array(f1_history), 'r',np.array(f1_history_val),'b')\n",
        "plt.ylabel('F1 multiclass score(unweighted)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "82c5ea8f03e0c61b8a1eddf7dd4fb0dcc59038309c931ef184c5056600baac5b"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('nlp2022-hw1')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "load.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}